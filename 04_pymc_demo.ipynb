{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tying it all Together\n",
    "\n",
    "<img src=\"https://images-mm.s3.amazonaws.com/Big_Lebowski_Rug_Blue_Shirt_POP.jpg\">\n",
    "\n",
    "## PyMC3 is:\n",
    "\n",
    "- a bunch of samplers\n",
    "- a DSL to define models\n",
    "- tools to assess sampling convergence\n",
    "- tools to apply (posterior) samples\n",
    "\n",
    "and has [great documentation](https://docs.pymc.io/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.tools as tls\n",
    "import pymc3 as pm\n",
    "\n",
    "from theano import shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Toy Example: Fitting a Quadratic Function\n",
    "\n",
    "Assume the function $f(x) = 2x^2 + 2x - 10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4, 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2*x**2 + 2*x - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(\n",
    "    data=[\n",
    "        go.Scatter(x=x, y=f(x), opacity=0.5, showlegend=False)\n",
    "    ],\n",
    "    layout={\n",
    "        'width': 800,\n",
    "        'height': 800\n",
    "    }\n",
    ")\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretending not to know the real function, let's generate 2 clusters of \"observed\" data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_observed = np.concatenate((\n",
    "    np.random.normal(loc=-2, scale=0.1, size=100),\n",
    "    np.random.normal(loc=1, scale=0.1, size=100)\n",
    "))\n",
    "x_observed_shared = shared(x_observed)  # a Theano shared variable\n",
    "y_observed = np.random.normal(loc=f(x_observed), scale=1)\n",
    "\n",
    "fig.add_scatter(x=x_observed, y=y_observed, mode='markers', opacity=0.8, showlegend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as non_linear_model:\n",
    "    # priors\n",
    "    b0 = pm.Normal('b0', mu=0, sd=100)\n",
    "    b1 = pm.Normal('b1', mu=1, sd=100)\n",
    "    b2 = pm.Normal('b2', mu=1, sd=100)\n",
    "    sigma = pm.HalfNormal('sigma', sd=1)\n",
    "    \n",
    "    mu = b0 + b1*x_observed_shared + b2*x_observed_shared**2\n",
    "    \n",
    "    # likelihood\n",
    "    y_likelihood = pm.Normal('y_likelihood', mu=mu, sd=sigma, observed=y_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with non_linear_model:\n",
    "    trace = pm.sample(2000, tune=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What's `tune`?\n",
    "- What's that `trace` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Trace Diagnostics\n",
    "\n",
    "#### mc_error\n",
    "The standard error of the trace, as in: standard deviation of batch means for a given number of batches.\n",
    "\n",
    "#### HPD\n",
    "Highest Posterior Density interval, i.e. the credible interval with minimum width for given $\\alpha$.\n",
    "\n",
    "#### Number of Effective Samples (`n_eff`)\n",
    "Estimate of Effective Sample Size, roughly given as the number of samples corrected for the amount of autocorrelation.\n",
    "\n",
    "#### $\\hat{R}$\n",
    "Gelman-Rubin diagnostic, i.e. the ratio between inter-chain and intra-chain variance.\n",
    "\n",
    "There are more [stats](https://docs.pymc.io/api/stats.html) and [diagnostics](https://docs.pymc.io/api/diagnostics.html) in PyMC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.autocorrplot(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why this convenient util is hidden so far away..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_df = pm.backends.tracetab.trace_to_dataframe(trace).drop('sigma', axis=1)\n",
    "trace_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Fit: Making Some Predictions Using the Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(-4, 4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(x, model):\n",
    "    return model.iloc[0].b0 + model.iloc[0].b1*x + model.iloc[0].b2*x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "for _ in range(n):\n",
    "    random_model = trace_df.sample(n=1)\n",
    "    fig.add_scatter(x=x_test, y=[apply_model(x, random_model) for x in x_test],\n",
    "                    mode='lines', opacity=0.1, line={'width': 0.5, 'color': 'grey', 'shape': 'spline'}, showlegend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.layout.title = f'{n} Random Models From the Trace'\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Checks\n",
    "\n",
    "Previously, `x_observed_shared` was declared to use our observed x values for \"fitting the model\" (i.e. sampling from the posterior). By updating this shared Theano variable with new values for $x$, it is possible to predict new $y$ values using the samples from the trace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_observed_shared.set_value(x_test)\n",
    "ppc = pm.sample_ppc(trace=trace, model=non_linear_model, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is _far less straightforward_ than e.g. sklearn's `predict()`!\n",
    "\n",
    "What is returned is a 3-d matrix with dimensions `n_samples` $\\times$ `size` $\\times$ `len(x)`. It's up to the user to decide what to do with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc['y_likelihood'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the HPD for the test xs \\[-4,4\\]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = ppc['y_likelihood'].reshape(-1, len(x_test))\n",
    "\n",
    "# to explain the above (which collapses the 'n_samples X size' dimensions into one):\n",
    "np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]], [[9, 10], [11, 12]]]).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd_all = np.apply_along_axis(pm.hpd, arr=y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_scatter(x=x_test, y=hpd_all[1], name='95% HPD upper bound', mode='lines', line={'shape': 'spline'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.add_scatter(x=x_test, y=hpd_all[0], name='95% HPD lower bound', mode='lines', line={'shape': 'spline'});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
